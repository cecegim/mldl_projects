{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MNIST\n",
    "\n",
    "- 인코딩된 바이너리 데이터를 디코딩하여 처리하는 방식 확인\n",
    "- 지도 학습\n",
    "- 학습용 데이터는 6만개, 테스트 데이터는 1만개\n",
    "- 결론\n",
    "    - 학습 후 새로운 데이터 입력시 판별\n",
    "    - 0~9까지의 손글씨 이미지를 판별\n",
    "    - 데이터는 url을 직접 획득해서, 원하는 곳에 다운로드 시키겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 절차\n",
    "\n",
    "|No|단계|내용|\n",
    "|:---:|:---|:---|\n",
    "|1|연구목표|- 손글씨 이미지(0-9)를 학습시켜서, 새로운 손글씨 이미지를 판별해 내는 머신러닝 모델을 구축<br>- 압축된 이미지를 압축해제<br>- 인코딩된 데이터를 디코딩 처리<br>- 28X28로 구성된 픽셀 이미지 데이터를 벡터화 처리<br>- 시스템 통합의 결과를 복 연구 목표를 설정해야 하지만 시스템 통합을 생략하므로 이부분은 생략|\n",
    "|2|데이터획득/수집|- http://yann.lecun.com/exdb/mnist/ 접속<br>- web scraping을 통해서 데이터의 URL 획득<br>- 지정된 위치에 다운로드->압축해제|\n",
    "|3|데이터준비/전처리|- 디코딩(내부구조를 알수 있는 인코딩 문서(MNIST Database) 필요)<br>- 에디언(Endian)처리<br>- 벡터화 처리|\n",
    "|4|데이터탐색/통찰/시각화분석|- 생략|\n",
    "|5|데이터모델링(머신러닝모델링)|- 분류 알고리즘 사용<br>- 알고리즘 선택->훈련용 데이터와 학습용 데이터 나눔->학습->예측->평가|\n",
    "|6|시스템통합|- 생략|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 획득/수집\n",
    "\n",
    "- 모듈 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup = BeautifulSoup(req.urlopen(rootUrl),'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4개의 url 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n",
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#모든 요소 tt중에 상위 4개가 링크\n",
    "for tt in soup.findAll('tt')[:4]:\n",
    "    print(tt.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[tt.a.string for tt in soup.findAll('tt')[:4]]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운로드>압축해제 <- 반복작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = './data/mnist'\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa00878871244c097fc075b97f143bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/train-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tqdm:진행율을 보여주는 모듈\n",
    "from tqdm import tqdm_notebook\n",
    "for file in tqdm_notebook(files):\n",
    "    print('소스',rootUrl + file)\n",
    "    local_path='%s/%s' % (savePath,file)\n",
    "    print('대상',local_path)\n",
    "    \n",
    "    #웹상에 존재하는 리소스를 로컬 디스크상에 직접 저장\n",
    "    req.urlretrieve(rootUrl + file,local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd7622fdd0344f2877fae2fd4bdb649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mnist/train-images-idx3-ubyte.gz\n",
      "./data/mnist/train-images-idx3-ubyte\n",
      "./data/mnist/train-labels-idx1-ubyte.gz\n",
      "./data/mnist/train-labels-idx1-ubyte\n",
      "./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "./data/mnist/t10k-images-idx3-ubyte\n",
      "./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "./data/mnist/t10k-labels-idx1-ubyte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#압축해제\n",
    "for file in tqdm_notebook(files):\n",
    "    #원본파일의 경로\n",
    "    ori_gzip_file='%s/%s' % (savePath,file)\n",
    "    print(ori_gzip_file)\n",
    "    #압축해제 파일의 경로\n",
    "    target_file='%s/%s' % (savePath,file[:-3])\n",
    "    print(target_file)\n",
    "    #압축해제\n",
    "    #gzip의 파일오픈 -> 읽기 -> 쓰기\n",
    "    with gzip.open(ori_gzip_file,'rb') as fg:\n",
    "        #읽기(압축해제를 수행했다)\n",
    "        tmp = fg.read()\n",
    "        #쓰기:일반파일로 기록\n",
    "        with open(target_file,'wb') as f:\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터준비/전처리\n",
    "\n",
    "- 디코딩(내부구조를 알수 있는 인코딩 문서(MNIST Database) 필요)\n",
    "- 에디언(Endian)처리(TCP/IP상에서 통신 수행시 중요)\n",
    "    - 컴퓨터 메모리와 같은 1차원 공간에 여러개의 연속된 데이터를 배열하는 방법\n",
    "    - 종류:바이트를 배치하는 오더(순서)를 앞에서부터 혹은 뒤에서부터 채우는가\n",
    "        - 0x12345678\n",
    "        - 빅 에디언 : 값을 앞에서부터 채운다\n",
    "            0x12 0x34 0x56 0x78\n",
    "        - 리틀 에디언 : 값을 뒤에서부터 채운다\n",
    "            0x78 0x56 0x34 0x12\n",
    "        - 위의 예는 정수값(4byte)을 예를 든것이고, 단지 값이 어떻게 기록됐는지만 이해하고, 그대로 값을 복원할 수 있으면 끝\n",
    "- 벡터화 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label file\n",
    "    - magic number : 4byte -> 에디안 체크\n",
    "    - label 수 : 4byte -> 에디안\n",
    "    - label 데이터 : 1byte -> 0~9 값\n",
    "    - 크기 = 4 + 4 + label수*1byte = 8 + 60000 = 60008byte\n",
    "- image file\n",
    "    - magic number : 4byte -> 에디안 체크\n",
    "    - 손글시 이미지 개수 : 4byte -> 에디안 체크\n",
    "    - 가로크기(픽셀수) : 4byte -> 에디안 체크\n",
    "    - 세로크기(픽셀수 : 4byte -> 에디안 체크\n",
    "    - 픽셀값 한개 한개 : unsigned 1byte(=8bit)(0~2^8-1 : 0~255(0xFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원데이터의 구조를 이해했으니, 구조에 맞춰서 데이터를 디코딩한다\n",
    "import struct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 10000\n",
      "2051 10000 28 28\n",
      "이미지파일의크기 7840016 bytes\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#테스트용 레이블 파일 처리\n",
    "label_f=open('./data/mnist/t10k-labels-idx1-ubyte','rb')\n",
    "#바이너리 데이터는 헤더부터 읽어서 데이터의 유효성이나 종류를 인지\n",
    "#MNIST 파일은 규격서에 high(빅) edian으로 수치값을 기술했다라고 확인되었다.\n",
    "#label파일은 헤더가 4+4=8byte이다(규격서기준)\n",
    "#high(빅) edian ->>\n",
    "#4 -> I(i의 대문자)\n",
    "#헤더 정보 추출\n",
    "magic_number, label_count = struct.unpack('>II',label_f.read(8))\n",
    "#magic_number : 2019 -> 레이블 파일이다\n",
    "#label_count : 1000 -> 데이터의 개수(레이블의 개수, 답의 개수)\n",
    "print(magic_number, label_count)\n",
    "\n",
    "image_f=open('./data/mnist/t10k-images-idx3-ubyte','rb')\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII',image_f.read(16))\n",
    "print(magic_number2, image_count, row, col)\n",
    "\n",
    "#헤더 정보를 기초로 반복 작업수행 : 정답추출, 이미지 추출\n",
    "#헤더크기=16+이미지1개데이터크기(28*28)*이미지총개수(10000)\n",
    "print('이미지파일의크기',4+4+4+4+10000*28*28,'bytes')\n",
    "\n",
    "#헤더 정보를 기초로 반복작업:정답추출, 이미지 추출\n",
    "for idx in range(image_count):\n",
    "    #정답 추출 : label_f를 통해서 1byte읽는다. 단, unsigned(부호없는, 양수) byte -> 'B'\n",
    "    label_tmp = struct.unpack('B', label_f.read(1)) #파일을 읽으면 읽은 만큼 누적으로 커서(파일포인터)위치이동\n",
    "    label=label_tmp[0]\n",
    "    print(label)\n",
    "    #이미지 추출\n",
    "    \n",
    "    #이미지 데이터의 벡터화\n",
    "\n",
    "image_f.close()\n",
    "label_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '84', '185', '159', '151', '60', '36', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '222', '254', '254', '254', '254', '241', '198', '198', '198', '198', '198', '198', '198', '198', '170', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '67', '114', '72', '114', '163', '227', '254', '225', '254', '254', '254', '250', '229', '254', '254', '140', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '17', '66', '14', '67', '67', '67', '59', '21', '236', '254', '106', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '83', '253', '209', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '22', '233', '255', '83', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '129', '254', '238', '44', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '59', '249', '254', '62', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '187', '5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '9', '205', '248', '58', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '126', '254', '182', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '75', '251', '240', '57', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '19', '221', '254', '166', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '203', '254', '219', '35', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '38', '254', '254', '77', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '31', '224', '254', '115', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '61', '242', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '254', '219', '40', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '207', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "label_f=open('./data/mnist/t10k-labels-idx1-ubyte','rb')\n",
    "image_f=open('./data/mnist/t10k-images-idx3-ubyte','rb')\n",
    "\n",
    "magic_number, label_count = struct.unpack('>II',label_f.read(8))\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII',image_f.read(16))\n",
    "\n",
    "#이미지 1개당 크기\n",
    "pixels=row*col #28x28\n",
    "for idx in range(image_count):\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    label=label_tmp[0]\n",
    "    #이미지 추출 -> 바이너리 데이터를 읽는다 -> 에디안은 관계 없음\n",
    "    binarryData = image_f.read(pixels)\n",
    "#     print(type(binarryData), len(binarryData),binarryData)\n",
    "    #픽셀값 하나하나를 문자열로 만들어서 리스트에 담는다\n",
    "    #바이너리 값은 0~255의 문자열로 변경했다\n",
    "    strData = list(map(lambda x:str(x), binarryData))\n",
    "    print(strData)\n",
    "    # csv에 한줄의 데이터로 기록 -> 1 + 784개를 기록 -> 1개의 데이터 표현\n",
    "    # 구분자 ,\n",
    "    \n",
    "    #pgm파일로 dump처리해서 확인(데이터의 유효성 확인)\n",
    "    \n",
    "    \n",
    "    #이미지 데이터의 벡터화\n",
    "    break\n",
    "    pass\n",
    "\n",
    "image_f.close()\n",
    "label_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f=open('./data/mnist/t10k-labels-idx1-ubyte','rb')\n",
    "image_f=open('./data/mnist/t10k-images-idx3-ubyte','rb')\n",
    "#csv 파일 오픈\n",
    "csv_f=open('./data/mnist/t10k.csv','w',encoding='utf-8')\n",
    "magic_number, label_count = struct.unpack('>II',label_f.read(8))\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII',image_f.read(16))\n",
    "\n",
    "pixels=row*col \n",
    "for idx in range(image_count):\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    label=label_tmp[0]\n",
    "    binarryData = image_f.read(pixels)\n",
    "    strData = list(map(lambda x:str(x), binarryData))\n",
    "    # csv에 한줄의 데이터로 기록 -> 1 + 784개를 기록 -> 1개의 데이터 표현\n",
    "    csv_f.write(str(label)+',')\n",
    "    csv_f.write(','.join(strData) + '\\n')\n",
    "    #pgm파일로 dump처리해서 확인(데이터의 유효성 확인)\n",
    "    if idx== 0 : #한번만 수행\n",
    "        with open('./data/mnist/%s.pgm' % label,'w', encoding='utf-8') as f:\n",
    "            f.write('P2 28 28 255\\n' + ' '.join(strData))\n",
    "    #이미지 데이터의 벡터화\n",
    "    break\n",
    "    pass\n",
    "\n",
    "image_f.close()\n",
    "label_f.close()\n",
    "csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_mnist_rawData(dataStyle='train',maxCount=0):\n",
    "    label_f=open(f'./data/mnist/{dataStyle}-labels-idx1-ubyte','rb')\n",
    "    image_f=open(f'./data/mnist/{dataStyle}-images-idx3-ubyte','rb')\n",
    "    csv_f=open(f'./data/mnist/{dataStyle}.csv','w',encoding='utf-8')\n",
    "    magic_number, label_count = struct.unpack('>II',label_f.read(8))\n",
    "    magic_number2, image_count, row, col = struct.unpack('>IIII',image_f.read(16))\n",
    "\n",
    "    if maxCount>=image_count:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count)\n",
    "        return\n",
    "    elif maxCount== -1:\n",
    "        maxCount = image_count\n",
    "    elif maxCount <-1:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count)\n",
    "        return\n",
    "    \n",
    "    pixels=row*col \n",
    "    for idx in (range(maxCount)):\n",
    "#         if idx >= maxCount : break\n",
    "        label_tmp = struct.unpack('B', label_f.read(1))\n",
    "        label=label_tmp[0]\n",
    "        binarryData = image_f.read(pixels)\n",
    "        strData = list(map(lambda x:str(x), binarryData))\n",
    "        csv_f.write(str(label)+',')\n",
    "        csv_f.write(','.join(strData) + '\\n')\n",
    "\n",
    "    image_f.close()\n",
    "    label_f.close()\n",
    "    csv_f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_mnist_rawData(dataStyle='train',maxCount=58000)\n",
    "decoding_mnist_rawData(dataStyle='t10k',maxCount=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M1] 데이터 품질 향상\n",
    "\n",
    "- 정확도를 96%목표로 머신러닝 모델을 개선\n",
    "\n",
    "    [사전조치]\n",
    "    - 머신러닝 모델을 이용하여 예측시 정확도가 떨어지면 데이터의 품질, 양을 검토한다\n",
    "    - 양을 점차적으로 늘린다\n",
    "        - 데이터의 개수를 늘리거나, 비율을 조정(훈련:테스트=75:25)\n",
    "    - 품질을 향상시킨다\n",
    "        - 정규화\n",
    "        - 차후에 적용가능한 내용 : PCA같은 비지도 학습의 차원축소(피처의 수를 줄인다)\n",
    "        \n",
    "    [모델개선조치]\n",
    "    - 알고리즘 교체\n",
    "    - 하이퍼파라미터 튜닝\n",
    "    - 파이프라인을 이용한 전처리기를 활용(품질향상)하여 향상\n",
    "    - 이런 교차 검증법을 활용하여 성능향상을 도모한다\n",
    "    - 이런 것들의 검증은 ROC곡선, AUC값 등으로 확인할 수도 있고, 교차 검증법의 결과로 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\t데이터탐색/통찰/시각화분석\n",
    "\n",
    "- skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 함수를 만든다 load_csv(dataType='train')\n",
    "# 현재 csv파일은 t10k.csv, train.csv\n",
    "# 출력 데이터 : csv 파일명\n",
    "# 입력 데이터 : {'labels':[],'images':[[]]}\n",
    "\n",
    "def load_csv(dataType='train'):\n",
    "    labels=list()\n",
    "    images=list()\n",
    "    with open(f'./data/mnist/{dataType}.csv','r') as f:\n",
    "        for line in f:\n",
    "            tmp=line.split(',')\n",
    "            labels.append(int(tmp[0]))\n",
    "            images.append(list(map(lambda x:int(x),tmp[1:])))\n",
    "    return {'labels':labels,'images':images}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(dataType='train'):\n",
    "    f = open(f'./data/mnist/{dataType}.csv', 'r')\n",
    "    \n",
    "    labels = list()\n",
    "    images = list()\n",
    "    \n",
    "    while True:\n",
    "        row = f.readline()\n",
    "        if not row: break\n",
    "        labels.append(int(row.split(',')[0]))\n",
    "        images.append(list(map(lambda x:int(x),row.split(',')[1:])))\n",
    "    f.close()\n",
    "    return { 'labels':labels, 'images':images }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=load_csv()\n",
    "test=load_csv('t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\t데이터모델링(머신러닝모델링)\n",
    "\n",
    "- 지도학습 데이터이므로, 정확도를 통해서 평가를 1차로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std_train=scaler.fit_transform(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 알고리즘 생성\n",
    "clf=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 데이터분류(위에서 완료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58000, 58000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['images']),len(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#4. 학습\n",
    "clf.fit(train['images'], train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 예측\n",
    "predict=clf.predict(scaler.transform(test['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. 평가\n",
    "metrics.accuracy_score(test['labels'],predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       219\n",
      "           1       0.11      1.00      0.21       287\n",
      "           2       0.00      0.00      0.00       276\n",
      "           3       0.00      0.00      0.00       254\n",
      "           4       0.00      0.00      0.00       275\n",
      "           5       0.00      0.00      0.00       221\n",
      "           6       0.00      0.00      0.00       225\n",
      "           7       0.00      0.00      0.00       257\n",
      "           8       0.00      0.00      0.00       242\n",
      "           9       0.00      0.00      0.00       244\n",
      "\n",
      "    accuracy                           0.11      2500\n",
      "   macro avg       0.01      0.10      0.02      2500\n",
      "weighted avg       0.01      0.11      0.02      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#7. 오차행렬(혼돈행렬)을 이용한 평가\n",
    "clf_report=metrics.classification_report(test['labels'],predict)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
