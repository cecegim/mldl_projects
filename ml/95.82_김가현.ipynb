{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MNIST\n",
    "\n",
    "- 인코딩된 바이너리 데이터를 디코딩하여 처리하는 방식 확인\n",
    "- 지도 학습\n",
    "- 학습용 데이터는 6만개, 테스트 데이터는 1만개\n",
    "- 결론\n",
    "    - 학습 후 새로운 데이터 입력시 판별\n",
    "    - 0~9까지의 손글씨 이미지를 판별\n",
    "    - 데이터는 url을 직접 획득해서, 원하는 곳에 다운로드 시키겠다\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 절차\n",
    "\n",
    "|No|단계|내용|\n",
    "|:---:|:---|:---|\n",
    "|1|연구목표|- 손글씨 이미지(0-9)를 학습시켜서, 새로운 손글씨 이미지를 판별해 내는 머신러닝 모델을 구축<br>- 압축된 이미지를 압축해제<br>- 인코딩된 데이터를 디코딩 처리<br>- 28X28로 구성된 픽셀 이미지 데이터를 벡터화 처리<br>- 시스템 통합의 결과를 복 연구 목표를 설정해야 하지만 시스템 통합을 생략하므로 이부분은 생략|\n",
    "|2|데이터획득/수집|- http://yann.lecun.com/exdb/mnist/ 접속<br>- web scraping을 통해서 데이터의 URL 획득<br>- 지정된 위치에 다운로드->압축해제|\n",
    "|3|데이터준비/전처리|- 디코딩(내부구조를 알수 있는 인코딩 문서(MNIST Database) 필요)<br>- 에디언(Endian)처리<br>- 벡터화 처리|\n",
    "|4|데이터탐색/통찰/시각화분석|- 생략|\n",
    "|5|데이터모델링(머신러닝모델링)|- 분류 알고리즘 사용<br>- 알고리즘 선택->훈련용 데이터와 학습용 데이터 나눔->학습->예측->평가|\n",
    "|6|시스템통합|- 생략|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 획득/수집\n",
    "\n",
    "- 모듈 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "import os, os.path, gzip\n",
    "import struct "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup = BeautifulSoup(req.urlopen(rootUrl),'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4개의 url 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 요소 tt중에 상위 4개가 링크\n",
    "for tt in soup.findAll('tt')[:4]:\n",
    "    print(tt.a.string)\n",
    "    \n",
    "files=[tt.a.string for tt in soup.findAll('tt')[:4]]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드>압축해제 <- 반복작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = './data/mnist'\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "    \n",
    "#tqdm:진행율을 보여주는 모듈\n",
    "from tqdm import tqdm_notebook\n",
    "for file in tqdm_notebook(files):\n",
    "    print('소스',rootUrl + file)\n",
    "    local_path='%s/%s' % (savePath,file)\n",
    "    print('대상',local_path)\n",
    "    \n",
    "    #웹상에 존재하는 리소스를 로컬 디스크상에 직접 저장\n",
    "    req.urlretrieve(rootUrl + file,local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#압축해제\n",
    "for file in tqdm_notebook(files):\n",
    "    #원본파일의 경로\n",
    "    ori_gzip_file='%s/%s' % (savePath,file)\n",
    "    print(ori_gzip_file)\n",
    "    #압축해제 파일의 경로\n",
    "    target_file='%s/%s' % (savePath,file[:-3])\n",
    "    print(target_file)\n",
    "    #압축해제\n",
    "    #gzip의 파일오픈 -> 읽기 -> 쓰기\n",
    "    with gzip.open(ori_gzip_file,'rb') as fg:\n",
    "        #읽기(압축해제를 수행했다)\n",
    "        tmp = fg.read()\n",
    "        #쓰기:일반파일로 기록\n",
    "        with open(target_file,'wb') as f:\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터준비/전처리\n",
    "\n",
    "- 디코딩(내부구조를 알수 있는 인코딩 문서(MNIST Database) 필요)\n",
    "- 에디언(Endian)처리(TCP/IP상에서 통신 수행시 중요)\n",
    "    - 컴퓨터 메모리와 같은 1차원 공간에 여러개의 연속된 데이터를 배열하는 방법\n",
    "    - 종류:바이트를 배치하는 오더(순서)를 앞에서부터 혹은 뒤에서부터 채우는가\n",
    "        - 0x12345678\n",
    "        - 빅 에디언 : 값을 앞에서부터 채운다\n",
    "            0x12 0x34 0x56 0x78\n",
    "        - 리틀 에디언 : 값을 뒤에서부터 채운다\n",
    "            0x78 0x56 0x34 0x12\n",
    "        - 위의 예는 정수값(4byte)을 예를 든것이고, 단지 값이 어떻게 기록됐는지만 이해하고, 그대로 값을 복원할 수 있으면 끝\n",
    "- 벡터화 처리\n",
    "- label file\n",
    "    - magic number : 4byte -> 에디안 체크\n",
    "    - label 수 : 4byte -> 에디안\n",
    "    - label 데이터 : 1byte -> 0~9 값\n",
    "    - 크기 = 4 + 4 + label수*1byte = 8 + 60000 = 60008byte\n",
    "- image file\n",
    "    - magic number : 4byte -> 에디안 체크\n",
    "    - 손글시 이미지 개수 : 4byte -> 에디안 체크\n",
    "    - 가로크기(픽셀수) : 4byte -> 에디안 체크\n",
    "    - 세로크기(픽셀수 : 4byte -> 에디안 체크\n",
    "    - 픽셀값 한개 한개 : unsigned 1byte(=8bit)(0~2^8-1 : 0~255(0xFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decoding_mnist_rawData(dataStyle='train',maxCount=0):\n",
    "    label_f=open(f'./data/mnist/{dataStyle}-labels-idx1-ubyte','rb')\n",
    "    image_f=open(f'./data/mnist/{dataStyle}-images-idx3-ubyte','rb')\n",
    "    csv_f=open(f'./data/mnist/{dataStyle}.csv','w',encoding='utf-8')\n",
    "    magic_number, label_count = struct.unpack('>II',label_f.read(8))\n",
    "    magic_number2, image_count, row, col = struct.unpack('>IIII',image_f.read(16))\n",
    "\n",
    "    if maxCount>image_count:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count)\n",
    "        return\n",
    "    elif maxCount== -1:\n",
    "        maxCount = image_count\n",
    "    elif maxCount <-1:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count)\n",
    "        return\n",
    "    \n",
    "    pixels=row*col \n",
    "    for idx in (range(maxCount)):\n",
    "#         if idx >= maxCount : break\n",
    "        label_tmp = struct.unpack('B', label_f.read(1))\n",
    "        label=label_tmp[0]\n",
    "        binarryData = image_f.read(pixels)\n",
    "        strData = list(map(lambda x:str(x), binarryData))\n",
    "        csv_f.write(str(label)+',')\n",
    "        csv_f.write(','.join(strData) + '\\n')\n",
    "\n",
    "    image_f.close()\n",
    "    label_f.close()\n",
    "    csv_f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_mnist_rawData(dataStyle='train',maxCount=30000)\n",
    "decoding_mnist_rawData(dataStyle='t10k',maxCount=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M1] 데이터 품질 향상\n",
    "\n",
    "- 정확도를 96%목표로 머신러닝 모델을 개선\n",
    "\n",
    "    [사전조치]\n",
    "    - 머신러닝 모델을 이용하여 예측시 정확도가 떨어지면 데이터의 품질, 양을 검토한다\n",
    "    - 양을 점차적으로 늘린다\n",
    "        - 데이터의 개수를 늘리거나, 비율을 조정(훈련:테스트=75:25)\n",
    "    - 품질을 향상시킨다\n",
    "        - 정규화\n",
    "        - 차후에 적용가능한 내용 : PCA같은 비지도 학습의 차원축소(피처의 수를 줄인다)\n",
    "        \n",
    "    [모델개선조치]\n",
    "    - 알고리즘 교체\n",
    "    - 하이퍼파라미터 튜닝\n",
    "    - 파이프라인을 이용한 전처리기를 활용(품질향상)하여 향상\n",
    "    - 이런 교차 검증법을 활용하여 성능향상을 도모한다\n",
    "    - 이런 것들의 검증은 ROC곡선, AUC값 등으로 확인할 수도 있고, 교차 검증법의 결과로 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_ex(dataType='train'):\n",
    "    labels=list()\n",
    "    images=list()\n",
    "    with open(f'./data/mnist/{dataType}.csv','r') as f:\n",
    "        for line in f:\n",
    "            tmp=line.split(',')\n",
    "            labels.append(int(tmp[0]))\n",
    "            images.append(list(map(lambda x:int(x)/,tmp[1:])))\n",
    "    return {'labels':labels,'images':images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=load_csv_ex()\n",
    "test=load_csv_ex('t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4\t데이터탐색/통찰/시각화분석\n",
    "\n",
    "- skip\n",
    "\n",
    "### 5\t데이터모델링(머신러닝모델링)\n",
    "\n",
    "- 지도학습 데이터이므로, 정확도를 통해서 평가를 1차로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 0, 4, 1, 9], [0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['labels'][:5],train['images'][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std_train=scaler.fit_transform(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 30000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['images']),len(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_std_train, train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=clf.predict(scaler.transform(test['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test['labels'],predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.95      0.96      0.95      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.96      0.94      0.95       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.92      0.95      0.94      1028\n",
      "           8       0.95      0.94      0.95       974\n",
      "           9       0.97      0.93      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report=metrics.classification_report(test['labels'],predict)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
